# Copyright 2022 CircuitNet. All rights reserved.

import os
# åœ¨å¯¼å…¥PyTorchä¹‹å‰è®¾ç½®CUDA_VISIBLE_DEVICESï¼Œç¡®ä¿åªä½¿ç”¨GPU 0
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

# æŠ‘åˆ¶å¸¸è§è­¦å‘Š
import warnings
warnings.filterwarnings("ignore", message=".*MMCV will release v2.0.0.*")
warnings.filterwarnings("ignore", message=".*A NumPy version.*is required for this version of SciPy.*")
warnings.filterwarnings("ignore", message=".*Importing from timm.models.layers is deprecated.*")
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

import json
import torch
import torch.optim as optim
from tqdm import tqdm
import gc

from datasets.build_dataset import build_dataset
from utils.losses import build_loss
from models.build_model import build_model
from utils.configs import Parser
from utils.lr_scheduler import CosineRestartLr
from math import cos, pi
from datetime import datetime








def checkpoint(model, epoch, save_path):
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    model_out_path = f"{save_path}/model_iters_{epoch}.pth"
    torch.save({'state_dict': model.state_dict()}, model_out_path)
    print("Checkpoint saved to {}".format(model_out_path))


# CosineRestartLrç±»ç°åœ¨ä»utils.lr_schedulerå¯¼å…¥ï¼Œä¸åŸå§‹ibUNetå®Œå…¨ä¸€è‡´


def train():
    now = datetime.now()

    argp = Parser()
    arg = argp.parser.parse_args()
    arg_dict = vars(arg)
    if arg.arg_file is not None:
        with open(arg.arg_file, "rt") as f:
            arg_dict.update(json.load(f))

    # ç¡®ä¿æŸäº›å‚æ•°æ˜¯æ•´æ•°ç±»å‹
    arg_dict["max_iters"] = int(arg_dict["max_iters"])

    if not os.path.exists(arg_dict["save_path"]):
        os.makedirs(arg_dict["save_path"])
    with open(os.path.join(arg_dict["save_path"], "arg.json"), "wt") as f:
        json.dump(arg_dict, f, indent=4)

    arg_dict["ann_file"] = arg_dict["ann_file_train"]
    arg_dict["test_mode"] = False

    # æ¨¡å‹åç§°æ˜ å°„
    model_display_names = {
        "Congestion_Prediction_Net": "ibUNet (Inception Boosted U-Net)",
        "GPDL": "GPDL",
        "GCNCongestion": "GCN",
        "EGEUNetCongestion": "EGE-UNet",
        "GraphSAGECongestion": "GraphSAGE",
        "RGCNCongestion": "RGCN",
        "RouteNet": "RouteNet",
        "SwinTransformerCongestion": "Swin Transformer",
        "VMUNet": "VM-UNet",
        "BRAUNet_Congestion": "BRAU-Net++",
        "GATCongestion": "GAT"
    }

    model_type = arg_dict.get('model_type', 'Unknown')
    display_name = model_display_names.get(model_type, model_type)

    # æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
    print("=" * 50)
    print("CircuitNet è®­ç»ƒå¼€å§‹")
    print("=" * 50)
    print(f"æ¨¡å‹: {display_name}")
    print(f"å·¥ä½œç›®å½•: {arg_dict['save_path']}")
    print(f"é…ç½®: batch_size={arg_dict['batch_size']}, lr={arg_dict['lr']}, max_iters={arg_dict['max_iters']}")
    print("=" * 50)

    print(f"===> Building model: {display_name}")
    # Initialize model parameters
    model = build_model(arg_dict)

    # è®¾å¤‡é€‰æ‹©å’Œæ¨¡å‹éƒ¨ç½² - ç¡®ä¿åªä½¿ç”¨å•ä¸ªGPU
    if not arg_dict["cpu"]:
        print("\n===> ä½¿ç”¨GPUè®­ç»ƒ")

        # ç¡®ä¿CUDAå¯ç”¨å¹¶é€‰æ‹©è®¾å¤‡
        if torch.cuda.is_available():
            device = torch.device('cuda')  # ç”±äºCUDA_VISIBLE_DEVICES='0'ï¼Œè¿™é‡Œä¼šè‡ªåŠ¨ä½¿ç”¨GPU 0
            print(f"âœ… ä½¿ç”¨GPU: {device}")
            print(f"âœ… å¯è§GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"âœ… å½“å‰CUDAè®¾å¤‡: cuda:{torch.cuda.current_device()}")
        else:
            device = torch.device('cpu')
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")

        model = model.to(device)
        print(f"âœ… æ¨¡å‹ç§»åŠ¨åˆ° {device}")
    else:
        print("\n===> ä½¿ç”¨CPUè®­ç»ƒ")
        device = torch.device('cpu')
        model = model.to(device)

    # æ›´æ–°arg_dictä¸­çš„è®¾å¤‡ä¿¡æ¯
    arg_dict["device"] = device

    # åœ¨è®¾å¤‡é€‰æ‹©å®Œæˆåæ„å»ºæ•°æ®é›†
    print("\n===> Loading datasets")

    # ç¦ç”¨pin_memoryé¿å…å¤šGPUä¸Šä¸‹æ–‡åˆå§‹åŒ–
    # pin_memoryå¯èƒ½å¯¼è‡´åœ¨å¤šä¸ªGPUä¸Šåˆ›å»ºCUDAä¸Šä¸‹æ–‡
    arg_dict["use_pin_memory"] = False
    

    # Initialize dataset
    dataset = build_dataset(arg_dict)

    # ç®€åŒ–æ•°æ®é›†ä¿¡æ¯æ˜¾ç¤º
    try:
        import pandas as pd
        train_csv = pd.read_csv(arg_dict['ann_file_train'])
        print(f"æ•°æ®é›†: {len(train_csv)} ä¸ªè®­ç»ƒæ ·æœ¬")
    except Exception as e:
        print(f"æ•°æ®é›†ä¿¡æ¯è·å–å¤±è´¥: {e}")

    # Build loss
    loss = build_loss(arg_dict)

    # Build Optimizer
    optimizer = optim.AdamW(
        model.parameters(),
        lr=arg_dict["lr"],
        betas=(0.9, 0.999),
        weight_decay=arg_dict["weight_decay"],
    )

    # Build lr scheduler
    cosine_lr = CosineRestartLr(arg_dict["lr"], [arg_dict["max_iters"]], [1], 1e-7)
    cosine_lr.set_init_lr(optimizer)

    epoch_loss = 0
    iter_num = 0
    print_freq = 100
    save_freq = 10000
    Show_freq = 1000

    lossList = []

    while iter_num < arg_dict['max_iters']:
        # æ™ºèƒ½è¿›åº¦æ¡ï¼šåœ¨æ—¥å¿—æ–‡ä»¶ä¸­ç®€æ´ï¼Œåœ¨ç»ˆç«¯ä¸­ç¾è§‚
        import sys
        is_logging_to_file = not sys.stdout.isatty()

        if is_logging_to_file:
            # æ—¥å¿—æ–‡ä»¶æ¨¡å¼ï¼šä¸æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œåªæ˜¾ç¤ºå…³é”®ä¿¡æ¯
            pbar = None
        else:
            # ç»ˆç«¯æ¨¡å¼ï¼šæ˜¾ç¤ºç¾è§‚çš„è¿›åº¦æ¡
            pbar = tqdm(total=print_freq, desc=f"Iter {iter_num//print_freq + 1}")

        batch_count = 0
        for feature, label, _ in dataset:
            # ä½¿ç”¨è®¾å¤‡
            device = arg_dict.get("device", torch.device('cpu'))

            try:
                input, target = feature.to(device), label.to(device)

                # åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶è¾“å‡ºè®¾å¤‡ä¿¡æ¯ç”¨äºè°ƒè¯•
                if iter_num == 1:
                    print(f"ğŸ” æ•°æ®è®¾å¤‡ä¿¡æ¯: inputåœ¨{input.device}, targetåœ¨{target.device}, æ¨¡å‹åœ¨{next(model.parameters()).device}")

            except RuntimeError as e:
                if "out of memory" in str(e).lower():
                    print(f"\nâŒ æ•°æ®ç§»åŠ¨æ—¶æ˜¾å­˜ä¸è¶³: {e}")
                    print("ğŸ”„ æ¸…ç†æ˜¾å­˜å¹¶é‡è¯•...")

                    # æ¸…ç†æ˜¾å­˜
                    if device.type == 'cuda':
                        torch.cuda.empty_cache()
                    gc.collect()

                    # é‡è¯•æ•°æ®ç§»åŠ¨
                    try:
                        input, target = feature.to(device), label.to(device)
                    except RuntimeError:
                        print("âš ï¸  æ˜¾å­˜ä»ç„¶ä¸è¶³ï¼Œå›é€€åˆ°CPU")
                        device = torch.device('cpu')
                        model = model.to(device)
                        arg_dict["device"] = device
                        input, target = feature.to(device), label.to(device)
                else:
                    raise e

            regular_lr = cosine_lr.get_regular_lr(iter_num)
            cosine_lr._set_lr(optimizer, regular_lr)

            prediction = model(input)

            optimizer.zero_grad()

            pixel_loss = loss(prediction, target)
            epoch_loss += pixel_loss.item()
            pixel_loss.backward()
            optimizer.step()

            iter_num += 1
            batch_count += 1

            # æ›´æ–°è¿›åº¦æ˜¾ç¤º
            if pbar:
                pbar.update(1)
            elif batch_count % 25 == 0:  # æ—¥å¿—æ¨¡å¼ï¼šæ¯25ä¸ªbatchæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                progress = (batch_count / print_freq) * 100
                print(f"    è®­ç»ƒè¿›åº¦: {batch_count}/{print_freq} ({progress:.1f}%)")

            if (iter_num % print_freq == 0 or iter_num==100):
                break

        # å…³é—­è¿›åº¦æ¡
        if pbar:
            pbar.close()

        # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œæ˜¾å­˜ä½¿ç”¨æƒ…å†µ
        avg_loss = epoch_loss / print_freq
        device = arg_dict.get("device", torch.device('cpu'))

        if device.type == 'cuda':
            try:
                # ç¡®ä¿æŸ¥è¯¢æ­£ç¡®çš„è®¾å¤‡
                current_device = torch.cuda.current_device()
                target_device_id = device.index if device.index is not None else 0

                allocated_memory = torch.cuda.memory_allocated(device) / 1024**3
                reserved_memory = torch.cuda.memory_reserved(device) / 1024**3

                # æ·»åŠ è®¾å¤‡ä¿¡æ¯ç”¨äºè°ƒè¯•
                print("===> Iters({}/{}): Loss: {:.4f} | GPUæ˜¾å­˜: {:.1f}GBå·²åˆ†é…, {:.1f}GBå·²ä¿ç•™ | è®¾å¤‡: {} (å½“å‰: cuda:{})".format(
                    iter_num, arg_dict['max_iters'], avg_loss, allocated_memory, reserved_memory, device, current_device))

                
            
            except Exception as e:
                print("===> Iters({}/{}): Loss: {:.4f} | GPUæ˜¾å­˜æŸ¥è¯¢å¤±è´¥: {}".format(
                    iter_num, arg_dict['max_iters'], avg_loss, e))
        else:
            print("===> Iters({}/{}): Loss: {:.4f} | ä½¿ç”¨CPUè®­ç»ƒ".format(
                iter_num, arg_dict['max_iters'], avg_loss))

        oneValue = avg_loss
        lossList.append(oneValue)
        if(len(lossList)>10):
            lossList.pop(0)
            sumValue =0
            for kk in range(len(lossList)):
                sumValue += lossList[kk]
            print("===> Average Loss: {:.4f}".format(sumValue / len(lossList)))

        if ((iter_num % save_freq == 0) or (100==iter_num)):
            checkpoint(model, iter_num, arg_dict['save_path'])

        if ((iter_num % Show_freq == 0) or (100==iter_num)):
            later = datetime.now()
            difference = (later - now).total_seconds()
            difference_minutes = int(difference // 60)
            difference_seconds = int(difference % 60)
            print('===> So far taining takes: '
                  + str(difference_minutes) + "(minutes) and "
                  + str(difference_seconds) + "(seconds)")

            max_iters = arg_dict['max_iters']
            expect_difference = difference*(max_iters/iter_num)
            difference_minutes = int(expect_difference // 60)
            difference_seconds = int(expect_difference % 60)
            print('===> Expected Time: '
                  + str(difference_minutes) + "(minutes) and "
                  + str(difference_seconds) + "(seconds)")

        epoch_loss = 0


if __name__ == "__main__":
    train()
